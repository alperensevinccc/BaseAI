"""
BaseAI Otonom GeliÅŸtirme, DoÄŸrulama ve Evrim DÃ¶ngÃ¼sÃ¼ (Nihai, Tam ve Eksiksiz SÃ¼rÃ¼m).

Bu modÃ¼l, BaseAI'nin kendi kod tabanÄ±nÄ± analiz etmesini, 
gÃ¶revleri tanÄ±mlamasÄ±nÄ±, LLM ile kod Ã¼retmesini/gÃ¼ncellemesini,
Ã¼retilen kodu 'ruff' ile lint etmesini, Git ile gÃ¼venlik kontrolÃ¼ yapmasÄ±nÄ±
ve sonuÃ§larÄ± diske yazmasÄ±nÄ± saÄŸlayan ana mantÄ±ÄŸÄ± iÃ§erir. 
Bu dosyanÄ±n kendisi BaseAI'nin en yÃ¼ksek kararlÄ±lÄ±k standardÄ±nÄ± temsil eder.
"""

from __future__ import annotations
import os
import time
import asyncio
import traceback
import json
import re
import subprocess
import tempfile
import shlex  # Subprocess komut parÃ§alarÄ±nÄ± gÃ¼venli ayrÄ±ÅŸtÄ±rmak iÃ§in eklendi
from typing import Dict, List, Any, Set, Optional, Tuple, Union # Union eklendi

# BaseAI Ã‡ekirdek BileÅŸenleri
from baseai.bridges.gpt import gpt_bridge, GPTConfig # GPT KÃ¶prÃ¼sÃ¼
from baseai.log.logger import core_logger as log    # Merkezi Logger

# --- Sabitler ve YapÄ±landÄ±rma ---
PROJECT_ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
BASE_AI_CORE_DIR = os.path.join(PROJECT_ROOT_DIR, 'baseai')

AUTODEV_BOOTSTRAP_FILES: Set[str] = {
    "baseai/autodev/evolution_reflector.py",
    "baseai/autodev/auto_refactor.py",
    "baseai/autodev/enterprise_loop.py",
    "baseai/autodev/self_heal_loop.py",
}
CONTEXT_IGNORE_DIRS: Set[str] = {
    ".venv", ".git", "__pycache__", ".idea", ".vscode", 
    "node_modules", "build", "dist", "logs", "tests",
    "autodev" 
}
CONTEXT_MAX_FILES: int = 150 # LLM'e gÃ¶nderilecek maksimum dosya sayÄ±sÄ±

# Desteklenen GÃ¶rev Tipleri
SUPPORTED_TASK_TYPES: Set[str] = {
    "YENÄ°_MODÃœL", 
    "MEVCUT_MODÃœLÃœ_GELÄ°ÅžTÄ°R", 
    "REFAKTÃ–R", 
    "TEST_YAZ",
}

# DoÄŸrulama ve GÃ¼venlik AyarlarÄ±
ENABLE_LINTING_CHECK: bool = True 
# Sadece Hata (E) ve Potansiyel Bug (F) kontrol edilir. W (UyarÄ±lar) atlanÄ±r.
RUFF_COMMAND: List[str] = [
    "ruff", "check", "--output-format=json", 
    "--force-exclude", 
    "--select=E,F,W", 
    "--ignore=E501,W291"  # W291 (Trailing Whitespace) kalÄ±cÄ± olarak yoksayÄ±lÄ±yor.
]
ENABLE_GIT_SAFETY_CHECK: bool = True 
ENABLE_GIT_AUTO_COMMIT: bool = False # VarsayÄ±lan olarak kapalÄ±!

# --- GeliÅŸmiÅŸ YardÄ±mcÄ± Fonksiyonlar (Subprocess ve Path GÃ¼venliÄŸi) ---

async def _validate_and_normalize_path(relative_path: str) -> Optional[str]:
    """
    Verilen gÃ¶receli yolu doÄŸrular, normalize eder ve mutlak yolunu dÃ¶ndÃ¼rÃ¼r.
    Proje kÃ¶kÃ¼ ve kritik dizin gÃ¼venlik kontrollerini iÃ§erir.
    """
    if not relative_path or not isinstance(relative_path, str):
        log.warning(f"[AutoDev|Path] GeÃ§ersiz veya boÅŸ dosya yolu: {relative_path}")
        return None
    try:
        abs_path = os.path.normpath(os.path.join(PROJECT_ROOT_DIR, relative_path))

        if not abs_path.startswith(PROJECT_ROOT_DIR):
            log.error(f"[AutoDev|Path|GÃ¼venlik] ðŸš¨ Engellendi! '{relative_path}' proje kÃ¶kÃ¼ dÄ±ÅŸÄ±na iÅŸaret ediyor.")
            return None
            
        critical_dirs = {".git", ".venv", ".tmp"} 
        path_parts = set(abs_path.split(os.sep))
        if critical_dirs.intersection(path_parts):
            log.error(f"[AutoDev|Path|GÃ¼venlik] ðŸš¨ Engellendi! '{relative_path}' kritik bir dizine iÅŸaret ediyor.")
            return None
             
        return abs_path
        
    except Exception as e:
        log.error(f"[AutoDev|Path] '{relative_path}' iÃ§in yol normalizasyon/doÄŸrulama hatasÄ±: {e}", exc_info=True)
        return None

async def _write_files_to_disk(file_bundle: Dict[str, str]) -> Tuple[List[str], List[str]]:
    """
    Ãœretilen dosya paketini alÄ±r ve diske yazar.
    """
    written_files: List[str] = []
    failed_files: List[str] = []
    
    if not isinstance(file_bundle, dict) or not file_bundle:
        log.warning("[AutoDev|Disk] YazÄ±lacak dosya iÃ§eren boÅŸ veya geÃ§ersiz bir paket alÄ±ndÄ±.")
        return written_files, failed_files 

    log.info(f"[AutoDev|Disk] {len(file_bundle)} adet dosya yazÄ±lacak...")
    for relative_path, content in file_bundle.items():
        if not content or not isinstance(content, str):
            log.warning(f"[AutoDev|Disk] '{relative_path}' iÃ§in boÅŸ veya geÃ§ersiz iÃ§erik atlandÄ±.")
            failed_files.append(relative_path)
            continue

        abs_path = await _validate_and_normalize_path(relative_path)
        if not abs_path:
            failed_files.append(relative_path)
            continue 

        try:
            os.makedirs(os.path.dirname(abs_path), exist_ok=True)
            
            if os.path.exists(abs_path):
                log.warning(f"[AutoDev|Disk] âš ï¸ Mevcut dosyanÄ±n Ã¼zerine yazÄ±lÄ±yor: {relative_path}")
                 
            with open(abs_path, "w", encoding="utf-8") as f: 
                f.write(content)
                
            log.info(f"[AutoDev|Disk] âœ… Dosya yazÄ±ldÄ±/gÃ¼ncellendi: {relative_path}")
            written_files.append(relative_path)

        except OSError as e:
            log.error(f"[AutoDev|Disk] âŒ Ä°ÅŸletim sistemi hatasÄ± ({abs_path}): {e}", exc_info=False)
            failed_files.append(relative_path)
        except Exception as e:
            log.error(f"[AutoDev|Disk] âŒ Yazma hatasÄ± ({relative_path}): {e}", exc_info=True)
            failed_files.append(relative_path)
            
    return written_files, failed_files

async def _get_codebase_context(root_dir: str, ignore_dirs: Set[str], max_files: int = CONTEXT_MAX_FILES) -> str:
    """
    .py dosyalarÄ±nÄ± tarar ve gÃ¶receli yollarÄ±nÄ± iÃ§eren bir metin oluÅŸturur.
    """
    log.debug(f"[AutoDev|Context] Kod tabanÄ± baÄŸlamÄ± taranÄ±yor (KÃ¶k: {root_dir}, Limit: {max_files})...")
    context_files: List[str] = []
    scanned_paths: Set[str] = set()

    priority_files = ["baseai/main.py", "baseai/core.py"] 
    for pf in priority_files:
        relative_path = pf
        abs_pf_path = os.path.normpath(os.path.join(PROJECT_ROOT_DIR, pf))
        if os.path.exists(abs_pf_path) and relative_path not in scanned_paths:
            context_files.append(relative_path)
            scanned_paths.add(relative_path)
            if len(context_files) >= max_files: break

    if len(context_files) < max_files:
        for current_root, dirs, files in os.walk(root_dir, topdown=True):
            dirs[:] = [d for d in dirs if d not in ignore_dirs and os.path.join(current_root, d) != BASE_AI_CORE_DIR] 
            
            for file in files:
                 if file.endswith(".py"):
                    full_path = os.path.join(current_root, file)
                    relative_path = os.path.relpath(full_path, PROJECT_ROOT_DIR)
                    if relative_path not in scanned_paths:
                        context_files.append(relative_path)
                        scanned_paths.add(relative_path)
                        if len(context_files) >= max_files: break
            if len(context_files) >= max_files: break 
                
    log.info(f"[AutoDev|Context] {len(context_files)} dosya baÄŸlam iÃ§in bulundu (Limit: {max_files}).")
    return "Mevcut Python DosyalarÄ± (Proje KÃ¶kÃ¼ne GÃ¶re):\n" + "\n".join(sorted(context_files))

async def _read_file_content(relative_path: str) -> Optional[str]:
    """Verilen gÃ¶receli yoldaki dosyanÄ±n iÃ§eriÄŸini gÃ¼venli bir ÅŸekilde okur."""
    abs_path = await _validate_and_normalize_path(relative_path)
    if not abs_path: return None
    try:
        if not os.path.exists(abs_path):
            log.warning(f"[AutoDev|Read] Dosya bulunamadÄ±: {relative_path}")
            return None
             
        file_size_mb = os.path.getsize(abs_path) / (1024 * 1024)
        if file_size_mb > 1: # 1 MB limiti
            log.warning(f"[AutoDev|Read] Dosya Ã§ok bÃ¼yÃ¼k ({file_size_mb:.2f}MB), iÃ§eriÄŸi okunmuyor: {relative_path}")
            return f"[HATA: Dosya iÃ§eriÄŸi Ã§ok bÃ¼yÃ¼k ({file_size_mb:.2f}MB)]"
             
        with open(abs_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        log.error(f"[AutoDev|Read] Dosya okuma hatasÄ± ({relative_path}): {e}", exc_info=True)
        return None

def _parse_task_description(description: str) -> Optional[Dict[str, str]]:
    """
    LLM'den gelen gÃ¶rev tanÄ±mÄ±nÄ± (Tip, Hedef, AÃ§Ä±klama formatÄ±nda) ayrÄ±ÅŸtÄ±rÄ±r.
    """
    if not description or not isinstance(description, str):
        log.warning("[AutoDev|Parse] AyrÄ±ÅŸtÄ±rÄ±lacak gÃ¶rev tanÄ±mÄ± boÅŸ veya geÃ§ersiz.")
        return None
    
    task = {"type": "UNKNOWN", "target": "N/A", "description": ""} 
    log.debug(f"[AutoDev|Parse] Ham gÃ¶rev tanÄ±mÄ± alÄ±nÄ±yor:\n{description}")

    try:
        type_match = re.search(r"GÃ¶rev\s*Tipi\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE)
        target_match = re.search(r"Hedef\s*Dosya\(lar\)\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE)
        desc_match = re.search(r"AÃ§Ä±klama\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE | re.DOTALL)

        raw_type = "UNKNOWN"
        if type_match:
            value = type_match.group(1).strip()
            cleaned_value = re.sub(r"^[^\w]+|[^\w]+$", "", value).strip()
            raw_type = cleaned_value.upper().replace(" ", "_")
        
        if raw_type not in SUPPORTED_TASK_TYPES:
            log.error(f"[AutoDev|Parse] âŒ LLM tarafÄ±ndan desteklenmeyen gÃ¶rev tipi Ã¼retildi: '{raw_type}'.")
            return None 
        task["type"] = raw_type
        
        if target_match: 
            value = target_match.group(1).strip()
            cleaned_value = re.sub(r"^[^\w./\\-]+|[^\w./\\-]+$", "", value).strip()
            task["target"] = re.sub(r'[`\'"]', '', cleaned_value)
        
        if desc_match: 
            task["description"] = desc_match.group(1).strip()
        
        if task["target"] == "N/A" and task["type"] != "UNKNOWN":
            log.error(f"[AutoDev|Parse] âŒ GÃ¶rev tipi '{task['type']}' iÃ§in Hedef Dosya(lar) gerekli ama bulunamadÄ±.")
            return None 
                 
        if not task["description"] and task["type"] != "UNKNOWN":
            log.error("[AutoDev|Parse] âŒ GÃ¶rev aÃ§Ä±klamasÄ± boÅŸ veya ayrÄ±ÅŸtÄ±rÄ±lamadÄ±.")
            return None

        log.info(f"[AutoDev|Parse] âœ… GÃ¶rev baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ± ve doÄŸrulandÄ±: Tip='{task['type']}', Hedef='{task['target']}'")
        return task
        
    except Exception as e:
        log.error(f"[AutoDev|Parse] GÃ¶rev tanÄ±mÄ± ayrÄ±ÅŸtÄ±rÄ±lÄ±rken kritik hata: {e}", exc_info=True)
        return None

async def _run_subprocess(command_parts: list[str]) -> tuple[bool, str, str]:
    """
    Verilen komut parÃ§alarÄ±nÄ± (liste) 'exec' kullanarak asenkron olarak Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    try:
        if not command_parts:
            log.warning("[AutoDev|Subprocess] Ã‡alÄ±ÅŸtÄ±rmak iÃ§in boÅŸ komut parÃ§alarÄ± alÄ±ndÄ±.")
            return False, "", "BoÅŸ komut."
            
        program = command_parts[0]
        args = command_parts[1:]

        # subprocess yerine asyncio.create_subprocess_exec kullanÄ±lÄ±yor, bu doÄŸru
        process = await asyncio.create_subprocess_exec(
            program,
            *args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout_bytes, stderr_bytes = await process.communicate()
        
        stdout = stdout_bytes.decode('utf-8').strip()
        stderr = stderr_bytes.decode('utf-8').strip()
        
        success = process.returncode == 0
        
        if not success and not stderr and stdout:
            # BazÄ± araÃ§lar (Ruff gibi) hatalarÄ± stdout'a basabilir
            stderr = stdout
            
        return success, stdout, stderr
        
    except Exception as e:
        command_str = " ".join(command_parts)
        log.error(f"[AutoDev|Subprocess] Alt sÃ¼reÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ± ('{command_str}'): {e}", exc_info=True)
        return False, "", f"Subprocess failed to run: {str(e)}"
    
# baseai/autodev/self_heal_loop.py iÃ§indeki _lint_code fonksiyonu

async def _lint_code(code_content: str) -> tuple[bool, str]:
    """
    Ãœretilen Python kodunu Ruff ile lint eder ve *gÃ¼venli* hatalarÄ± dÃ¼zeltmeye Ã§alÄ±ÅŸÄ±r.
    """
    success, output, stderr = False, "", ""  
    temp_dir = os.path.join(PROJECT_ROOT_DIR, ".tmp")
    os.makedirs(temp_dir, exist_ok=True) 
    temp_file_name: Optional[str] = None 

    try:
        # 1. Kod iÃ§eriÄŸini geÃ§ici dosyaya yazma
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding='utf-8', dir=temp_dir) as temp_file:
            temp_file.write(code_content)
            temp_file_name = temp_file.name
            # DosyayÄ± kapatmadan Ruff'un okumasÄ± iÃ§in flush yap
            temp_file.flush() 
        
        # --- KRÄ°TÄ°K ADIM: 1. Ruff DÃ¼zeltme Denemesi (inplace) ---
        # AmaÃ§: W291, W292 ve F541 gibi gÃ¼venli ve basit hatalarÄ± dÃ¼zeltmek.
        fix_command = [
            "ruff", "check", "--fix", 
            "--force-exclude", 
            "--select=E,F,W", 
            "--ignore=E501,W291",  # W291 Trailing Whitespace'i GÃœVENLÄ° atla
            temp_file_name
        ]
        
        log.debug(f"[AutoDev|Lint|Fix] Ruff dÃ¼zeltme denemesi: {' '.join(fix_command)}")
        
        # Subprocess yerine doÄŸrudan os.system veya subprocess.run kullanmak async'i bloke eder.
        # Bu nedenle asyncio.create_subprocess_exec kullanmaya devam ediyoruz.
        fix_success, fix_output, fix_stderr = await _run_subprocess(fix_command)

        if not fix_success:
             # EÄŸer Ruff dÃ¼zeltme komutu baÅŸarÄ±sÄ±z olursa (Ã¶rn: Ruff kurulu deÄŸil)
             error_msg = fix_stderr or fix_output
             return False, f"Linting failed (Ruff fix execution error): {error_msg}"


        # 4. DÃ¼zeltilmiÅŸ Kodu Oku
        with open(temp_file_name, "r", encoding='utf-8') as f:
            corrected_code_content = f.read()

        # 5. Son Onay KontrolÃ¼ (DÃ¼zeltme sonrasÄ± kalan kritik hatalar var mÄ±?)
        check_command = [
            "ruff", "check", "--output-format=json", 
            "--force-exclude", 
            "--select=E,F,W", 
            "--ignore=E501,W291",  # W291 Trailing Whitespace'i GÃœVENLÄ° atla
            temp_file_name
        ]
        success, output, stderr = await _run_subprocess(check_command)

        if not success:
             error_msg = stderr or output or "Son onay Ruff komutu baÅŸarÄ±sÄ±z oldu."
             return False, f"Linting failed (Final check execution error): {error_msg}"
        
        # JSON Ã§Ä±ktÄ±sÄ±nÄ± kontrol et
        try:
            lint_errors = json.loads(output)
            
            if not lint_errors:
                 # TÃ¼m hatalar dÃ¼zeltildi, listemiz boÅŸ. BAÅžARIDIR.
                 return True, "Linting passed (Autofix applied successfully)."

            # DÃ¼zeltilemeyen hatalar kaldÄ± (E, F seviyesinde)
            error_summaries = []
            for error in lint_errors:
                 code = error.get('code', 'N/A')
                 line = error.get('location',{}).get('row')
                 message = error.get('message', 'N/A')
                 error_summaries.append(f"{code} (L{line}): {message}")

            first_summary = error_summaries[0]
            # Kodu geri yÃ¼kle (content'i dÃ¼zeltilmiÅŸ kod ile deÄŸiÅŸtir)
            code_content = corrected_code_content 
            return False, f"Linting failed after autofix ({len(error_summaries)} remaining): {first_summary}"

        except json.JSONDecodeError:
            error_msg = stderr or output or "Son onay Ruff'tan bozuk JSON geldi."
            return False, f"Linting failed (Final check returned unparsable JSON): {error_msg}"

    except Exception as e:
        log.error(f"[AutoDev|Lint] Linting sÄ±rasÄ±nda beklenmedik kritik hata: {e}", exc_info=True)
        return False, f"Unexpected internal linting error: {e}"

    finally:
        if temp_file_name and os.path.exists(temp_file_name):
            os.remove(temp_file_name)
            log.debug(f"[AutoDev|Lint] GeÃ§ici dosya silindi: {temp_file_name}")

async def _check_git_status(abs_filepath: str) -> Tuple[bool, str]:
    """
    Verilen dosyanÄ±n Git durumunu kontrol eder.
    """
    if not ENABLE_GIT_SAFETY_CHECK:
        log.debug("[AutoDev|Git] Git gÃ¼venlik kontrolÃ¼ devre dÄ±ÅŸÄ±.")
        return True, "Git safety check disabled."
        
    git_dir = os.path.join(PROJECT_ROOT_DIR, ".git")
    if not os.path.exists(git_dir) or not os.path.isdir(git_dir):
        log.warning("[AutoDev|Git] Proje bir Git deposu deÄŸil. GÃ¼venlik kontrolÃ¼ atlanÄ±yor.")
        return True, "Not a Git repository."

    if not abs_filepath.startswith(PROJECT_ROOT_DIR):
        log.warning(f"[AutoDev|Git] Dosya yolu ({abs_filepath}) proje kÃ¶kÃ¼ dÄ±ÅŸÄ±nda. Kontrol atlanÄ±yor.")
        return True, "File outside project root." 

    command = ["git", "status", "--porcelain", abs_filepath]
    success, stdout, stderr = await _run_subprocess(command)
    
    if not success:
        log.error(f"[AutoDev|Git] 'git status' komutu Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {stderr}")
        return False, f"Failed to run git status: {stderr}" 

    if not stdout:
        log.debug(f"[AutoDev|Git] Dosya durumu temiz veya takip edilmiyor: {os.path.relpath(abs_filepath, PROJECT_ROOT_DIR)}")
        return True, "File is clean or untracked."
    else:
        log.critical(
            f"[AutoDev|Git|GÃ¼venlik] ðŸš¨ YAZMA ENGELLENDÄ°! "
            f"'{os.path.relpath(abs_filepath, PROJECT_ROOT_DIR)}' dosyasÄ±nda kaydedilmemiÅŸ deÄŸiÅŸiklikler var. "
            f"Git Status: '{stdout.strip()}'"
        )
        return False, f"Uncommitted changes detected: {stdout.strip()}"


async def _git_add_commit(abs_filepaths: List[str], task_description: str) -> bool:
    """YazÄ±lan dosyalarÄ± Git'e ekler ve commit atar."""
    if not ENABLE_GIT_AUTO_COMMIT:
        log.debug("[AutoDev|Git] Otomatik commit devre dÄ±ÅŸÄ±.")
        return False 
        
    if not abs_filepaths:
        log.warning("[AutoDev|Git] Commit atÄ±lacak dosya bulunamadÄ±.")
        return False

    git_dir = os.path.join(PROJECT_ROOT_DIR, ".git")
    if not os.path.exists(git_dir) or not os.path.isdir(git_dir):
        log.warning("[AutoDev|Git] Proje bir Git deposu deÄŸil. Otomatik commit atlanÄ±yor.")
        return False

    valid_paths_to_add = [p for p in abs_filepaths if p and p.startswith(PROJECT_ROOT_DIR)]
    if not valid_paths_to_add:
        log.warning("[AutoDev|Git] Eklenecek geÃ§erli dosya yolu bulunamadÄ±.")
        return False

    log.info(f"[AutoDev|Git] {len(valid_paths_to_add)} dosya Git'e ekleniyor...")
    add_command = ["git", "add"] + valid_paths_to_add
    success_add, _, stderr_add = await _run_subprocess(add_command)
    if not success_add:
        log.error(f"[AutoDev|Git] 'git add' baÅŸarÄ±sÄ±z oldu: {stderr_add}")
        return False

    log.info("[AutoDev|Git] DeÄŸiÅŸiklikler commit ediliyor...")
    commit_subject = f"feat(AutoDev): Apply changes for task - {task_description[:70]}"
    if len(task_description) > 70: commit_subject += "..."
    
    file_list_str = "\n- ".join(os.path.relpath(p, PROJECT_ROOT_DIR) for p in valid_paths_to_add[:3])
    if len(valid_paths_to_add) > 3: file_list_str += "\n- ..."
    
    commit_message = f"{commit_subject}\n\nFiles changed:\n- {file_list_str}"

    commit_command = ["git", "commit", "-m", commit_message]
    success_commit, stdout_commit, stderr_commit = await _run_subprocess(commit_command)
    
    if not success_commit and "nothing to commit" in (stdout_commit + stderr_commit):
        log.warning("[AutoDev|Git] Commit atÄ±lacak yeni deÄŸiÅŸiklik bulunamadÄ± (belki sadece formatlama?).")
        return True 
    elif not success_commit:
        log.error(f"[AutoDev|Git] 'git commit' baÅŸarÄ±sÄ±z oldu: {stderr_commit}")
        log.warning("[AutoDev|Git] Dosyalar 'git add' yapÄ±ldÄ± ancak commit edilemedi. Manuel kontrol gerekebilir.")
        return False
        
    log.info(f"[AutoDev|Git] âœ… DeÄŸiÅŸiklikler otomatik olarak commit edildi.")
    return True

# --- ANA EVRÄ°MSEL DÃ–NGÃœ FONKSÄ°YONU ---

async def run_once() -> Dict[str, Any]:
    """
    BaseAI Otonom Evrim DÃ¶ngÃ¼sÃ¼nÃ¼n tek bir iterasyonunu Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    start_time = time.monotonic()
    log.info("[AutoDev|Evrim] â–¶ï¸ Evrimsel DÃ¶ngÃ¼ Ä°terasyonu BaÅŸlÄ±yor (Nihai SÃ¼rÃ¼m)...")
    
    result: Dict[str, Any] = {
        "success": False, "task_type": "N/A", "task_target": "N/A",
        "task_description": "N/A", "files_generated": [], "files_lint_failed": [], 
        "files_git_blocked": [], "files_written": [], "files_failed_write": [], 
        "error": None
    }
    
    task_type: str = "N/A"
    task_description: str = "N/A"
    target_file_paths: List[str] = []
    task_target_str: str = "N/A" 

    try:
        bridge = await gpt_bridge() 
        
        # --- AdÄ±m 1: Bootstrap KontrolÃ¼ ---
        # Bu dosya dahil tÃ¼m kritik dosyalarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
        for file_rel_path in AUTODEV_BOOTSTRAP_FILES:
             abs_path = await _validate_and_normalize_path(file_rel_path)
             if not abs_path or not os.path.exists(abs_path):
                 log.critical(f"[AutoDev|Evrim|FATAL] Temel AutoDev dosyasÄ± eksik: {file_rel_path}.")
                 result["error"] = f"Missing bootstrap file: {file_rel_path}"; return result 

        # --- AdÄ±m 2: Durum DeÄŸerlendirme (Kod BaÄŸlamÄ±) ---
        code_context = await _get_codebase_context(BASE_AI_CORE_DIR, CONTEXT_IGNORE_DIRS)
        if "[HATA:" in code_context:
             log.error("[AutoDev|Evrim] Kod tabanÄ± baÄŸlamÄ± alÄ±namadÄ±.")
             result["error"] = "Failed to get codebase context."; return result

        # --- AdÄ±m 3: Dinamik GÃ¶rev Ãœretimi ---
        log.info("[AutoDev|Evrim] ðŸŽ¯ Bir sonraki geliÅŸtirme gÃ¶revi LLM'den isteniyor...")
        task_generation_prompt = (
            f"**AmaÃ§:** BaseAI'nin otonom evrimi iÃ§in bir sonraki adÄ±mÄ± belirle.\n"
            f"**Mevcut Dosyalar:**\n```\n{code_context}\n```\n"
            f"**Ä°zin Verilen GÃ¶rev Tipleri:** {', '.join(SUPPORTED_TASK_TYPES)}\n\n"
            "**Ä°stek:** Bu bilgilere gÃ¶re, BaseAI iÃ§in **bir sonraki en mantÄ±klÄ± geliÅŸtirme gÃ¶revini** aÅŸaÄŸÄ±daki **KESÄ°N FORMATTA** tanÄ±mla. Sadece bu 3 satÄ±rÄ± yaz, baÅŸka hiÃ§bir ÅŸey ekleme:\n"
            "```text\n"
            "GÃ¶rev Tipi: [SeÃ§tiÄŸin gÃ¶rev tipi]\n"
            "Hedef Dosya(lar): [Ä°lgili dosya yolu/yollarÄ±]\n"
            "AÃ§Ä±klama: [GÃ¶revin 1 cÃ¼mlelik Ã¶zeti]\n"
            "```\n"
            "**Ã–RNEK YANIT 1:**\n"
            "```text\n"
            "GÃ¶rev Tipi: YENÄ°_MODÃœL\n"
            "Hedef Dosya(lar): baseai/core/memory_manager.py\n"
            "AÃ§Ä±klama: Uzun sÃ¼reli hafÄ±za yÃ¶netimi iÃ§in yeni bir modÃ¼l oluÅŸtur.\n"
            "```\n"
            "**SENÄ°N YANITIN (SADECE 3 SATIR):**"
        )
        try:
             next_task_raw = await bridge.generate_text(task_generation_prompt)
             log.info(f"[AutoDev|Evrim] ðŸŽ¯ LLM GÃ¶rev Ã–nerisi (Ham):\n{next_task_raw}")
             task_details = _parse_task_description(next_task_raw) 
             if not task_details:
                 result["error"] = "LLM desteklenmeyen/ayrÄ±ÅŸtÄ±rÄ±lamayan bir gÃ¶rev tanÄ±mÄ± Ã¼retti."
                 log.error(f"[AutoDev|Evrim] âŒ GÃ¶rev ayrÄ±ÅŸtÄ±rÄ±lamadÄ± veya desteklenmiyor. YanÄ±t:\n{next_task_raw}")
                 result["success"] = False; return result
                 
             task_type = task_details['type']
             task_description = task_details['description']
             task_target_str = task_details['target'] 
             target_file_paths = [re.sub(r'[`\'"]', '', p.strip()) for p in task_target_str.split(',') if p.strip()]
             
             result.update(task_details) 
             log.info(f"[AutoDev|Evrim] âœ… GÃ¶rev Belirlendi ve DoÄŸrulandÄ±: [{task_type}] {task_target_str}") 
        except Exception as e:
             log.error(f"[AutoDev|Evrim] âŒ GÃ¶rev Ã¼retimi sÄ±rasÄ±nda LLM hatasÄ±: {e}", exc_info=True)
             result["error"] = f"Failed to generate/parse next task: {e}"; return result

        # --- AdÄ±m 4: GÃ¶rev YÃ¼rÃ¼tme Ä°Ã§in Talimat/BaÄŸlam HazÄ±rlama --- 
        execution_instruction: str = ""; execution_context: str = ""; execution_rules: List[str] = []
        
        if task_type in ["MEVCUT_MODÃœLÃœ_GELÄ°ÅžTÄ°R", "REFAKTÃ–R", "TEST_YAZ"]:
             if not target_file_paths: result["error"] = f"GÃ¶rev tipi '{task_type}' iÃ§in hedef dosya gerekli."; return result
             file_contents = {}; all_content_read = True
             for file_path in target_file_paths:
                 content = await _read_file_content(file_path);
                 if content is None: all_content_read = False; log.error(f"[AutoDev|Evrim] âŒ Hedef dosya okunamadÄ±: {file_path}."); break
                 file_contents[file_path] = content
             if not all_content_read: result["error"] = f"Target file(s) not readable for modification"; return result
             
             if len(file_contents) == 1: 
                 execution_context = list(file_contents.values())[0]
             else: 
                 context_parts = [f"# --- START FILE: {fp} ---\n{fc}\n# --- END FILE: {fp} ---" for fp, fc in file_contents.items()]
                 execution_context = "\n\n".join(context_parts)

             execution_instruction = (f"**ROL:** ...\n**GÃ–REV TÄ°PÄ°:** {task_type}\n**HEDEF DOSYA(LAR):** {task_target_str}\n\n**MEVCUT KOD:**\n```python\n{execution_context}\n```\n\n**Ä°STENEN DEÄžÄ°ÅžÄ°KLÄ°K:** {task_description}\n\n**Ã‡IKTI FORMATI:** JSON (`{{ \"{task_target_str}\": \"tam_gÃ¼ncel_kod\" }}`).")
             execution_rules = [ "[KESÄ°N] Ã‡Ä±ktÄ± formatÄ±: JSON...", f"[KESÄ°N] JSON anahtar(lar)Ä±: `{task_target_str}`.", "[KESÄ°N] Mevcut kodu KORU.", "[KESÄ°N] SADECE isteneni deÄŸiÅŸtir.", "[KALÄ°TE] Python 3.11+...", "[KALÄ°TE] Google Docstring...", "[KALÄ°TE] Type Hinting...", "[KALÄ°TE] PEP8...", "[KALÄ°TE] Hata YÃ¶netimi...", "[KALÄ°TE] ModÃ¼lerlik...", "[KALÄ°TE] Loglama...", "[KALÄ°TE] BaseAI entegrasyonu...", "[KALÄ°TE] Okunabilirlik...", "[DOÄžRULAMA] Kod `ruff ...` komutundan HATASIZ geÃ§melidir."]

        elif task_type == "YENÄ°_MODÃœL":
             if not target_file_paths or len(target_file_paths) != 1: result["error"] = "YENÄ°_MODÃœL iÃ§in tek hedef dosya gerekir."; return result
             target_file = target_file_paths[0] 
             execution_context = code_context 
             execution_instruction = (f"**ROL:** ...\n**GÃ–REV TÄ°PÄ°:** {task_type}\n**OLUÅžTURULACAK DOSYA:** `{target_file}`\n\n**GÃ–REV AÃ‡IKLAMASI:** {task_description}\n\n**MEVCUT PROJE YAPISI:**\n```\n{execution_context}\n```\n\n**Ä°STEK:** ... `{target_file}` ... oluÅŸtur.\n\n**Ã‡IKTI FORMATI:** ...JSON (`{{ \"{target_file}\": \"tam_kod\" }}`).")
             execution_rules = [ "[KESÄ°N] Ã‡Ä±ktÄ± formatÄ±: JSON...", f"[KESÄ°N] JSON anahtarÄ±: `{target_file}`.", "[KESÄ°N] Mevcut dosyalarÄ± deÄŸiÅŸtirme.", "[KALÄ°TE] Python 3.11+...", "[KALÄ°TE] Google Docstring...", "[KALÄ°TE] Type Hinting...", "[KALÄ°TE] PEP8...", "[KALÄ°TE] Hata YÃ¶netimi...", "[KALÄ°TE] ModÃ¼lerlik...", "[KALÄ°TE] Loglama...", "[KALÄ°TE] BaseAI entegrasyonu...", "[KALÄ°TE] Okunabilirlik...", "[DOÄžRULAMA] Kod `ruff ...` komutundan HATASIZ geÃ§melidir."]
        
        # --- AdÄ±m 5: GÃ¶rev YÃ¼rÃ¼tme (Kod Ãœretimi/GÃ¼ncelleme) ---      
        log.info(f"[AutoDev|Evrim] âš™ï¸ GÃ¶rev yÃ¼rÃ¼tÃ¼lÃ¼yor: {task_description[:100]}...")
        file_bundle = await bridge.generate_files(execution_instruction, execution_context, rules=execution_rules)

        # --- AdÄ±m 6: YanÄ±tÄ± DoÄŸrula (Format) ---    
        if not file_bundle or not isinstance(file_bundle, dict) or "error" in file_bundle:
            error_msg = file_bundle.get("error", "Bilinmeyen kÃ¶prÃ¼ hatasÄ±") if isinstance(file_bundle, dict) else "GeÃ§ersiz veya boÅŸ yanÄ±t (YÃ¼rÃ¼tme)"
            log.error(f"[AutoDev|Evrim] âŒ GÃ¶rev yÃ¼rÃ¼tme sÄ±rasÄ±nda GPT'den dosya paketi alÄ±namadÄ±: {error_msg}")
            result["error"] = f"LLM failed during task execution: {error_msg}"; return result 
            
        result["files_generated"] = list(file_bundle.keys())
        generated_files_set = set(result["files_generated"])
        expected_files_exec = set(target_file_paths) 
        
        if not expected_files_exec.issubset(generated_files_set):
             log.error(f"[AutoDev|Evrim] âŒ GPT yÃ¼rÃ¼tme sonucu beklenen hedef dosyalarÄ± iÃ§ermiyor! Beklenen: {expected_files_exec}, DÃ¶nen: {generated_files_set}")
             result["error"] = "LLM execution result missing target file(s)"; return result
             
        log.info(f"[AutoDev|Evrim] âœ… GPT'den {len(file_bundle)} dosyalÄ±k yÃ¼rÃ¼tme sonucu alÄ±ndÄ±.")

        # --- AdÄ±m 7: Linting ve GÃ¼venlik Kontrolleri ---     
        files_to_write: Dict[str, str] = {}; abs_paths_to_commit: List[str] = [] 
        lint_failed_details: Dict[str, str] = {}
        
        for relative_path, content in file_bundle.items():
            if relative_path not in expected_files_exec: 
                 log.warning(f"[AutoDev|Evrim] âš ï¸ LLM beklenmeyen dosya dÃ¶ndÃ¼rdÃ¼, yoksayÄ±lÄ±yor: {relative_path}"); continue
                 
            # Linting kontrolÃ¼
            lint_passed, lint_message = await _lint_code(content) 
            if not lint_passed:
                log.error(f"[AutoDev|Evrim] âŒ Ãœretilen kod LINT KONTROLÃœNÃœ GEÃ‡EMEDÄ°: {relative_path}. Mesaj: {lint_message}")
                result["files_lint_failed"].append(relative_path); lint_failed_details[relative_path] = lint_message; continue 

            # Yol ve GÃ¼venlik kontrolÃ¼
            abs_path = await _validate_and_normalize_path(relative_path)
            if not abs_path: 
                log.error(f"[AutoDev|Evrim] âŒ Lint geÃ§miÅŸ dosyanÄ±n yolu geÃ§ersiz: {relative_path}. YazÄ±lmayacak.")
                result["files_failed_write"].append(relative_path); continue 
            
            # Git KontrolÃ¼
            is_safe, git_status_msg = await _check_git_status(abs_path)
            if not is_safe:
                log.critical(f"[AutoDev|Evrim] ðŸš¨ YAZMA GÃœVENLÄ°K ENGELÄ°: {relative_path}. Sebep: {git_status_msg}")
                result["files_git_blocked"].append(relative_path); continue 
            
            files_to_write[relative_path] = content
            abs_paths_to_commit.append(abs_path) 

        # --- AdÄ±m 8: DosyalarÄ± Diske Yaz ---    
        if not files_to_write:
             error_parts = []
             if result["files_lint_failed"]: error_parts.append(f"{len(result['files_lint_failed'])} file(s) failed lint check")
             if result["files_git_blocked"]: error_parts.append(f"{len(result['files_git_blocked'])} file(s) blocked by Git status")
             error_detail = "; ".join(error_parts) if error_parts else "No valid files generated or passed checks."
             log.warning(f"[AutoDev|Evrim] âš ï¸ YazÄ±lacak geÃ§erli dosya yok ({error_detail}). GÃ¶rev tamamlanamadÄ±.")
             result["error"] = error_detail
             result["success"] = False
        else:
            written_files, failed_write = await _write_files_to_disk(files_to_write)
            result["files_written"] = written_files
            result["files_failed_write"].extend(failed_write) 

            # SonuÃ§ Durumunu Belirle
            all_targets_written = expected_files_exec.issubset(set(written_files)) 
            no_failures = not result["files_lint_failed"] and not result["files_git_blocked"] and not result["files_failed_write"]
            
            if all_targets_written and no_failures:
                result["success"] = True
                log.info("[AutoDev|Evrim] âœ… GÃ¶rev baÅŸarÄ±yla tamamlandÄ± ve tÃ¼m hedefler yazÄ±ldÄ±.")
                # --- AdÄ±m 9: Otomatik Commit ---
                if abs_paths_to_commit: await _git_add_commit(abs_paths_to_commit, result['task_description'])
            else: # KÄ±smi baÅŸarÄ± veya tam baÅŸarÄ±sÄ±zlÄ±k
                result["success"] = False
                errors = []
                if result["files_lint_failed"]: errors.append(f"{len(result['files_lint_failed'])} lint errors")
                if result["files_git_blocked"]: errors.append(f"{len(result['files_git_blocked'])} Git blocks")
                if result["files_failed_write"]: errors.append(f"{len(result['files_failed_write'])} write errors")
                if not all_targets_written: errors.append("Not all targets written")
                result["error"] = "; ".join(errors) if errors else "Unknown validation/write failure"
                log.error(f"[AutoDev|Evrim] âŒ GÃ¶rev tamamlanamadÄ± veya kÄ±smen tamamlandÄ±. Hatalar: {result['error']}")
                if lint_failed_details: # Lint hatalarÄ±nÄ± logla
                     log.error("[AutoDev|Evrim] Lint Hata DetaylarÄ±:")
                     for fname, msg in lint_failed_details.items():
                          log.error(f"  File: {fname} -> {msg}")

    except Exception as e:
        detailed_error = traceback.format_exc()
        log.critical(f"[AutoDev|Evrim] ðŸ’¥ DÃ¶ngÃ¼de beklenmeyen kritik hata: {e}\n{detailed_error}")
        result["error"] = f"CRITICAL_EVOLUTION_FAILURE: {e}"
        result["success"] = False

    finally:
        # DetaylÄ± SonuÃ§ Loglama (result sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ kullan)
        end_time = time.monotonic(); duration = end_time - start_time
        status = "BAÅžARILI" if result.get("success", False) else "BAÅžARISIZ"
        log.info(f"--- [AutoDev|Evrim] Ä°TERASYON SONUCU ---")
        log.info(f" Durum: {status}"); 
        log.info(f" GÃ¶rev Tipi: {result.get('task_type', 'N/A')}") 
        log.info(f" Hedef(ler): {result.get('task_target', 'N/A')}")
        log.info(f" AÃ§Ä±klama: {result.get('task_description', 'N/A')[:150]}...")
        log.info(f" Ãœretilen: {len(result.get('files_generated',[]))}, YazÄ±lan: {len(result.get('files_written',[]))}")
        log.info(f" BaÅŸarÄ±sÄ±z (Lint/Git/Yazma): {len(result.get('files_lint_failed',[]))}/{len(result.get('files_git_blocked',[]))}/{len(result.get('files_failed_write',[]))}")
        log.info(f" SÃ¼re: {duration:.2f}s")
        if result.get("error"): log.error(f" Hata DetayÄ±: {result.get('error')}")
        log.info(f"--- Ä°TERASYON SONUCU BÄ°TTÄ° ---")
             
    return result