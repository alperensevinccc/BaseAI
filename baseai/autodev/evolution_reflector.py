"""
BaseAI Stratejik Evrim DÃ¶ngÃ¼sÃ¼ (Evolution Reflector)
NÄ°HAÄ° SÃœRÃœM - Tam Otonomi BaÅŸlangÄ±cÄ±

Bu modÃ¼l, BaseAI'nin harici LLM baÄŸÄ±mlÄ±lÄ±ÄŸÄ±nÄ± kÄ±rmak iÃ§in 
gerekli olan iÃ§sel modÃ¼lleri inÅŸa etme sÃ¼recini yÃ¶netir.
Lokal LLM'i (Ollama) bir araÃ§ olarak kullanarak, kendi 
stratejik planlama ve kod analiz yeteneklerini inÅŸa eder.
"""

from __future__ import annotations
import os
import time
import asyncio
import traceback
import json
import re
import tempfile
import shlex
from typing import Dict, List, Any, Set, Optional, Tuple, Union, Callable, Awaitable

# BaseAI Ã‡ekirdek BileÅŸenleri
# Harici baÄŸÄ±mlÄ±lÄ±k kaldÄ±rÄ±ldÄ±. Lokal kÃ¶prÃ¼ye geÃ§iliyor.
from baseai.bridges.local_llm_bridge import local_llm_bridge 
from baseai.log.logger import core_logger as log    # Merkezi Logger

# --- Stabilize EdilmiÅŸ YardÄ±mcÄ± Fonksiyonlar ---
# self_heal_loop'tan gerekli olan ve kararlÄ±lÄ±ÄŸÄ± kanÄ±tlanmÄ±ÅŸ 
# tÃ¼m yardÄ±mcÄ± fonksiyonlar buraya entegre edildi.

PROJECT_ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
BASE_AI_CORE_DIR = os.path.join(PROJECT_ROOT_DIR, 'baseai')

# --- NÄ°HAÄ° DÃœZELTME (NameError): EVOLUTION_DATA_FILE global scope'a taÅŸÄ±ndÄ±. ---
EVOLUTION_DATA_FILE = os.path.join(PROJECT_ROOT_DIR, 'evolution_data.json')

AUTODEV_BOOTSTRAP_FILES: Set[str] = {
    "baseai/autodev/evolution_reflector.py",
    "baseai/autodev/self_heal_loop.py", 
}
CONTEXT_IGNORE_DIRS: Set[str] = {
    ".venv", ".git", "__pycache__", ".idea", ".vscode", 
    "node_modules", "build", "dist", "logs", "tests",
    "autodev" 
}
CONTEXT_MAX_FILES: int = 150 

SUPPORTED_TASK_TYPES: Set[str] = {
    "YENÄ°_MODÃœL", 
    "MEVCUT_MODÃœLÃœ_GELÄ°ÅTÄ°R", 
    "REFAKTÃ–R", 
    "TEST_YAZ",
}

ENABLE_GIT_SAFETY_CHECK: bool = True 
ENABLE_GIT_AUTO_COMMIT: bool = True 

async def _validate_and_normalize_path(relative_path: str) -> Optional[str]:
    """GÃ¶receli yolu doÄŸrular, normalize eder ve mutlak yolunu dÃ¶ndÃ¼rÃ¼r."""
    if not relative_path or not isinstance(relative_path, str):
        log.warning(f"[AutoDev|Path] GeÃ§ersiz veya boÅŸ dosya yolu: {relative_path}")
        return None
    try:
        abs_path = os.path.normpath(os.path.join(PROJECT_ROOT_DIR, relative_path))
        if not abs_path.startswith(PROJECT_ROOT_DIR):
            log.error(f"[AutoDev|Path|GÃ¼venlik] ğŸš¨ Engellendi! '{relative_path}' proje kÃ¶kÃ¼ dÄ±ÅŸÄ±na iÅŸaret ediyor.")
            return None
        critical_dirs = {".git", ".venv", ".tmp"} 
        path_parts = set(abs_path.split(os.sep))
        if critical_dirs.intersection(path_parts):
            log.error(f"[AutoDev|Path|GÃ¼venlik] ğŸš¨ Engellendi! '{relative_path}' kritik bir dizine iÅŸaret ediyor.")
            return None
        return abs_path
    except Exception as e:
        log.error(f"[AutoDev|Path] '{relative_path}' iÃ§in yol normalizasyon/doÄŸrulama hatasÄ±: {e}", exc_info=True)
        return None

async def _write_files_to_disk(file_bundle: Dict[str, str]) -> Tuple[List[str], List[str]]:
    """Ãœretilen dosya paketini alÄ±r ve diske yazar."""
    written_files: List[str] = []
    failed_files: List[str] = []
    
    if not isinstance(file_bundle, dict) or not file_bundle:
        log.warning("[AutoDev|Disk] YazÄ±lacak dosya iÃ§eren boÅŸ veya geÃ§ersiz bir paket alÄ±ndÄ±.")
        return written_files, failed_files 

    log.info(f"[AutoDev|Disk] {len(file_bundle)} adet dosya yazÄ±lacak...")
    for relative_path, content in file_bundle.items():
        if not content or not isinstance(content, str):
            log.warning(f"[AutoDev|Disk] '{relative_path}' iÃ§in boÅŸ veya geÃ§ersiz iÃ§erik atlandÄ±.")
            failed_files.append(relative_path)
            continue

        abs_path = await _validate_and_normalize_path(relative_path)
        if not abs_path:
            failed_files.append(relative_path)
            continue 

        try:
            os.makedirs(os.path.dirname(abs_path), exist_ok=True)
            if os.path.exists(abs_path):
                log.warning(f"[AutoDev|Disk] âš ï¸ Mevcut dosyanÄ±n Ã¼zerine yazÄ±lÄ±yor: {relative_path}")
            with open(abs_path, "w", encoding="utf-8") as f: 
                f.write(content)
            log.info(f"[AutoDev|Disk] âœ… Dosya yazÄ±ldÄ±/gÃ¼ncellendi: {relative_path}")
            written_files.append(relative_path)
        except Exception as e:
            log.error(f"[AutoDev|Disk] âŒ Yazma hatasÄ± ({relative_path}): {e}", exc_info=True)
            failed_files.append(relative_path)
            
    return written_files, failed_files

async def _get_codebase_context(root_dir: str, ignore_dirs: Set[str], max_files: int = CONTEXT_MAX_FILES) -> str:
    """.py dosyalarÄ±nÄ± tarar ve gÃ¶receli yollarÄ±nÄ± iÃ§eren bir metin oluÅŸturur."""
    log.debug(f"[AutoDev|Context] Kod tabanÄ± baÄŸlamÄ± taranÄ±yor (KÃ¶k: {root_dir}, Limit: {max_files})...")
    context_files: List[str] = []
    scanned_paths: Set[str] = set()
    try:
        priority_files = ["baseai/main.py", "baseai/core.py"] 
        for pf in priority_files:
            relative_path = pf
            abs_pf_path = os.path.normpath(os.path.join(PROJECT_ROOT_DIR, pf))
            if os.path.exists(abs_pf_path) and relative_path not in scanned_paths:
                context_files.append(relative_path)
                scanned_paths.add(relative_path)
                if len(context_files) >= max_files: break

        if len(context_files) < max_files:
            for current_root, dirs, files in os.walk(root_dir, topdown=True):
                dirs[:] = [d for d in dirs if d not in ignore_dirs and os.path.join(current_root, d) != BASE_AI_CORE_DIR] 
                for file in files:
                     if file.endswith(".py"):
                        full_path = os.path.join(current_root, file)
                        relative_path = os.path.relpath(full_path, PROJECT_ROOT_DIR)
                        if relative_path not in scanned_paths:
                            context_files.append(relative_path)
                            scanned_paths.add(relative_path)
                            if len(context_files) >= max_files: break
                if len(context_files) >= max_files: break 
    except Exception as e:
        log.error(f"[AutoDev|Context] Kod tabanÄ± taranÄ±rken hata: {e}", exc_info=True)
        return "[HATA: Kod baÄŸlamÄ± alÄ±namadÄ±]"

    log.info(f"[AutoDev|Context] {len(context_files)} dosya baÄŸlam iÃ§in bulundu (Limit: {max_files}).")
    return "Mevcut Python DosyalarÄ± (Proje KÃ¶kÃ¼ne GÃ¶re):\n" + "\n".join(sorted(context_files))

async def _read_file_content(relative_path: str) -> Optional[str]:
    """Verilen gÃ¶receli yoldaki dosyanÄ±n iÃ§eriÄŸini gÃ¼venli bir ÅŸekilde okur."""
    abs_path = await _validate_and_normalize_path(relative_path)
    if not abs_path: return None
    try:
        if not os.path.exists(abs_path):
            log.warning(f"[AutoDev|Read] Dosya bulunamadÄ±: {relative_path}")
            return None
        file_size_mb = os.path.getsize(abs_path) / (1024 * 1024)
        if file_size_mb > 1:
            log.warning(f"[AutoDev|Read] Dosya Ã§ok bÃ¼yÃ¼k ({file_size_mb:.2f}MB), iÃ§eriÄŸi okunmuyor: {relative_path}")
            return f"[HATA: Dosya iÃ§eriÄŸi Ã§ok bÃ¼yÃ¼k ({file_size_mb:.2f}MB)]"
        with open(abs_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        log.error(f"[AutoDev|Read] Dosya okuma hatasÄ± ({relative_path}): {e}", exc_info=True)
        return None

def _parse_task_description(description: str) -> Optional[Dict[str, str]]:
    """LLM'den gelen gÃ¶rev tanÄ±mÄ±nÄ± ayrÄ±ÅŸtÄ±rÄ±r."""
    if not description or not isinstance(description, str):
        log.warning("[AutoDev|Parse] AyrÄ±ÅŸtÄ±rÄ±lacak gÃ¶rev tanÄ±mÄ± boÅŸ veya geÃ§ersiz.")
        return None
    task = {"type": "UNKNOWN", "target": "N/A", "description": ""} 
    try:
        type_match = re.search(r"GÃ¶rev\s*Tipi\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE)
        target_match = re.search(r"Hedef\s*Dosya\(lar\)\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE)
        desc_match = re.search(r"AÃ§Ä±klama\s*:\s*(.*)", description, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        raw_type = "UNKNOWN"
        if type_match:
            value = type_match.group(1).strip()
            cleaned_value = re.sub(r"^[^\w]+|[^\w]+$", "", value).strip()
            raw_type = cleaned_value.upper().replace(" ", "_")
        if raw_type not in SUPPORTED_TASK_TYPES:
            log.error(f"[AutoDev|Parse] âŒ LLM tarafÄ±ndan desteklenmeyen gÃ¶rev tipi Ã¼retildi: '{raw_type}'.")
            return None 
        task["type"] = raw_type
        if target_match: 
            value = target_match.group(1).strip()
            cleaned_value = re.sub(r"^[^\w./\\-]+|[^\w./\\-]+$", "", value).strip()
            task["target"] = re.sub(r'[`\'"]', '', cleaned_value)
        if desc_match: 
            task["description"] = desc_match.group(1).strip()
        if task["target"] == "N/A" and task["type"] != "UNKNOWN":
            log.error(f"[AutoDev|Parse] âŒ GÃ¶rev tipi '{task['type']}' iÃ§in Hedef Dosya(lar) gerekli ama bulunamadÄ±.")
            return None 
        if not task["description"] and task["type"] != "UNKNOWN":
            log.error("[AutoDev|Parse] âŒ GÃ¶rev aÃ§Ä±klamasÄ± boÅŸ veya ayrÄ±ÅŸtÄ±rÄ±lamadÄ±.")
            return None
        log.info(f"[AutoDev|Parse] âœ… GÃ¶rev baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ± ve doÄŸrulandÄ±: Tip='{task['type']}', Hedef='{task['target']}'")
        return task
    except Exception as e:
        log.error(f"[AutoDev|Parse] GÃ¶rev tanÄ±mÄ± ayrÄ±ÅŸtÄ±rÄ±lÄ±rken kritik hata: {e}", exc_info=True)
        return None

async def _run_subprocess(command_parts: list[str]) -> tuple[bool, str, str]:
    """Verilen komut parÃ§alarÄ±nÄ± (liste) 'exec' kullanarak asenkron olarak Ã§alÄ±ÅŸtÄ±rÄ±r."""
    try:
        if not command_parts:
            return False, "", "BoÅŸ komut."
        program = command_parts[0]
        args = command_parts[1:]
        process = await asyncio.create_subprocess_exec(
            program, *args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout_bytes, stderr_bytes = await process.communicate()
        stdout = stdout_bytes.decode('utf-8').strip()
        stderr = stderr_bytes.decode('utf-8').strip()
        success = process.returncode == 0
        if not success and not stderr and stdout:
            stderr = stdout
        return success, stdout, stderr
    except Exception as e:
        command_str = " ".join(command_parts)
        log.error(f"[AutoDev|Subprocess] Alt sÃ¼reÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ± ('{command_str}'): {e}", exc_info=True)
        return False, "", f"Subprocess failed to run: {str(e)}"

async def _lint_code(code_content: str) -> tuple[bool, str, str]:
    """
    Ãœretilen Python kodunu Ruff ile lint eder ve *gÃ¼venli* hatalarÄ± dÃ¼zeltir.
    Returns: (lint_passed, error_message, corrected_code)
    """
    temp_dir = os.path.join(PROJECT_ROOT_DIR, ".tmp")
    os.makedirs(temp_dir, exist_ok=True) 
    temp_file_name: Optional[str] = None 
    corrected_code_content = code_content # VarsayÄ±lan olarak orijinal kod

    try:
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding='utf-8', dir=temp_dir) as temp_file:
            temp_file.write(code_content)
            temp_file_name = temp_file.name
            temp_file.flush() 
        
        # --- AdÄ±m 1: Ruff DÃ¼zeltme Denemesi (inplace) ---
        fix_command = [
            "ruff", "check", "--fix", "--force-exclude", 
            "--select=E,F,W", 
            "--ignore=E501,W291", # W291 (Trailing Whitespace) kalÄ±cÄ± olarak yoksayÄ±lÄ±yor
            temp_file_name
        ]
        log.debug(f"[AutoDev|Lint|Fix] Ruff dÃ¼zeltme denemesi: {' '.join(fix_command)}")
        fix_success, fix_output, fix_stderr = await _run_subprocess(fix_command)

        if not fix_success:
             # EÄŸer Ruff --fix komutu 0 olmayan bir kodla dÃ¶nerse (Ã¶rn: dÃ¼zeltilemeyen hata kaldÄ±ysa),
             # bu bir hata deÄŸildir, sadece dÃ¼zeltmenin tamamlanmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.
             # Ancak, stderr varsa, bu Ruff'un Ã§alÄ±ÅŸamadÄ±ÄŸÄ±nÄ± gÃ¶sterir (Ã¶rn: ruff kurulu deÄŸil)
             if fix_stderr:
                return False, f"Linting failed (Ruff fix execution error): {fix_stderr}", code_content
             # Sadece Ã§Ä±ktÄ± (output) varsa, bu dÃ¼zeltilemeyen hatalardÄ±r.
             log.warning(f"[AutoDev|Lint|Fix] Ruff dÃ¼zeltilemeyen hatalar buldu, son kontrol yapÄ±lacak.")
        
        # --- AdÄ±m 2: DÃ¼zeltilmiÅŸ Kodu Oku ---
        with open(temp_file_name, "r", encoding='utf-8') as f:
            corrected_code_content = f.read()

        # --- AdÄ±m 3: Son Onay KontrolÃ¼ (Sadece Kritik Hatalar: E, F) ---
        check_command = [
            "ruff", "check", "--output-format=json", "--force-exclude", 
            "--select=E,F", # Sadece E ve F'yi kontrol et
            "--ignore=E501", 
            temp_file_name
        ]
        log.debug(f"[AutoDev|Lint|Check] Son onay kontrolÃ¼: {' '.join(check_command)}")
        success, output, stderr = await _run_subprocess(check_command)

        if not success:
             error_msg = stderr or output or "Son onay Ruff komutu baÅŸarÄ±sÄ±z oldu."
             return False, f"Linting failed (Final check execution error): {error_msg}", corrected_code_content
        
        # --- AdÄ±m 4: JSON Ã‡Ä±ktÄ±sÄ±nÄ± Yorumla ---
        try:
            # Output boÅŸsa (veya sadece whitespace ise), KESÄ°N BAÅARIDIR.
            if not output:
                 return True, "Linting passed (Autofix applied).", corrected_code_content

            lint_errors = json.loads(output)
            
            # JSON parse edildi ve hata listesi boÅŸtuysa, BAÅARIDIR.
            if not lint_errors:
                 return True, "Linting passed (JSON output empty/no errors).", corrected_code_content
            
            # DÃ¼zeltilemeyen (E/F) hatalar kaldÄ±
            error_summaries = [f"{e.get('code','N/A')} (L{e.get('location',{}).get('row')}): {e.get('message','N/A')}" for e in lint_errors]
            first_summary = error_summaries[0]
            log.error(f"[AutoDev|Evrim] Ruff dÃ¼zeltme sonrasÄ± kritik hatalar buldu ({len(error_summaries)} adet).")
            return False, f"Linting failed after autofix ({len(error_summaries)} remaining): {first_summary}", corrected_code_content

        except json.JSONDecodeError:
            # Ruff RC=0 dÃ¶ndÃ¼ ama JSON bozuk. 
            error_msg = stderr or output or "Bilinmeyen ruff JSON hatasÄ±."
            log.error(f"[AutoDev|Evrim] Ruff baÅŸarÄ±lÄ± (RC=0) ancak JSON ayrÄ±ÅŸtÄ±rÄ±lamadÄ±. Ham Ã§Ä±ktÄ±: {error_msg}")
            return False, f"Linting failed (Final check returned unparsable JSON with RC=0): {error_msg}", corrected_code_content

    except Exception as e:
        log.error(f"[AutoDev|Lint] Linting sÄ±rasÄ±nda beklenmedik kritik hata: {e}", exc_info=True)
        return False, f"Unexpected internal linting error: {e}", code_content
    finally:
        if temp_file_name and os.path.exists(temp_file_name):
            try:
                os.remove(temp_file_name)
            except OSError as e:
                log.warning(f"[AutoDev|Lint] GeÃ§ici dosya silinemedi: {e}")

async def _check_git_status(abs_filepath: str) -> Tuple[bool, str]:
    """
    Verilen dosyanÄ±n Git durumunu kontrol eder.
    """
    if not ENABLE_GIT_SAFETY_CHECK:
        return True, "Git safety check disabled."
        
    # --- YENÄ° GÃœVENLÄ°K KONTROLÃœ (YENÄ°_MODÃœL iÃ§in) ---
    # EÄŸer dosya henÃ¼z mevcut deÄŸilse (YENÄ°_MODÃœL durumu), 
    # Git kontrolÃ¼ yapmaya gerek yoktur, yazmak gÃ¼venlidir.
    if not os.path.exists(abs_filepath):
        log.debug(f"[AutoDev|Git] Hedef dosya mevcut deÄŸil ({os.path.relpath(abs_filepath, PROJECT_ROOT_DIR)}). Yazma gÃ¼venli.")
        return True, "File does not exist (new module)."
    git_dir = os.path.join(PROJECT_ROOT_DIR, ".git")
    if not os.path.exists(git_dir):
        log.warning("[AutoDev|Git] Proje bir Git deposu deÄŸil. GÃ¼venlik kontrolÃ¼ atlanÄ±yor.")
        return True, "Not a Git repository."
    command = ["git", "status", "--porcelain", abs_filepath]
    success, stdout, stderr = await _run_subprocess(command)
    if not success:
        return False, f"Failed to run git status: {stderr}" 
    if not stdout:
        return True, "File is clean or untracked."
    else:
        log.critical(f"[AutoDev|Git|GÃ¼venlik] ğŸš¨ YAZMA ENGELLENDÄ°! '{os.path.relpath(abs_filepath, PROJECT_ROOT_DIR)}' dosyasÄ±nda kaydedilmemiÅŸ deÄŸiÅŸiklikler var.")
        return False, f"Uncommitted changes detected: {stdout.strip()}"

async def _git_add_commit(abs_filepaths: List[str], task_description: str) -> bool:
    """YazÄ±lan dosyalarÄ± Git'e ekler ve commit atar."""
    if not ENABLE_GIT_AUTO_COMMIT or not abs_filepaths:
        return False
    git_dir = os.path.join(PROJECT_ROOT_DIR, ".git")
    if not os.path.exists(git_dir):
        return False
    valid_paths_to_add = [p for p in abs_filepaths if p and p.startswith(PROJECT_ROOT_DIR)]
    if not valid_paths_to_add:
        return False
    add_command = ["git", "add"] + valid_paths_to_add
    success_add, _, stderr_add = await _run_subprocess(add_command)
    if not success_add:
        log.error(f"[AutoDev|Git] 'git add' baÅŸarÄ±sÄ±z oldu: {stderr_add}"); return False
    commit_subject = f"feat(AutoDev): Apply changes for task - {task_description[:70]}"
    file_list_str = "\n- ".join(os.path.relpath(p, PROJECT_ROOT_DIR) for p in valid_paths_to_add[:3])
    if len(valid_paths_to_add) > 3: file_list_str += "\n- ..."
    commit_message = f"{commit_subject}\n\nFiles changed:\n- {file_list_str}"
    commit_command = ["git", "commit", "-m", commit_message]
    success_commit, stdout_commit, stderr_commit = await _run_subprocess(commit_command)
    if not success_commit and "nothing to commit" in (stdout_commit + stderr_commit):
        return True # Hata yok
    elif not success_commit:
        log.error(f"[AutoDev|Git] 'git commit' baÅŸarÄ±sÄ±z oldu: {stderr_commit}"); return False
    log.info(f"[AutoDev|Git] âœ… DeÄŸiÅŸiklikler otomatik olarak commit edildi.")
    push_command = ["git", "push", "origin", "main"]
    success_push, stdout_push, stderr_push = await _run_subprocess(push_command)

    if not success_push:
        log.error(f"[AutoDev|Git] 'git push' baÅŸarÄ±sÄ±z oldu: {stderr_push}")
        return False # Push baÅŸarÄ±sÄ±z olursa tÃ¼m iÅŸlemi baÅŸarÄ±sÄ±z say
    
    log.info("[AutoDev|Git] âœ… DeÄŸiÅŸiklikler baÅŸarÄ±yla GitHub'a yÃ¼klendi.")

    return True

# --- GeÃ§miÅŸ Analiz FonksiyonlarÄ± ---

def load_evolution_data() -> Dict[str, List]:
    """Tarihsel evrim verilerini JSON dosyasÄ±ndan yÃ¼kler."""
    if os.path.exists(EVOLUTION_DATA_FILE):
        try:
            with open(EVOLUTION_DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data.get('iterations'), list):
                    return data
                else:
                    log.warning(f"'{EVOLUTION_DATA_FILE}' dosyasÄ± geÃ§ersiz formatta. SÄ±fÄ±rlanÄ±yor.")
                    return {"iterations": []} 
        except (json.JSONDecodeError, OSError) as e:
            log.error(f"'{EVOLUTION_DATA_FILE}' okunamadÄ±: {e}. SÄ±fÄ±rlanÄ±yor.")
            return {"iterations": []}
    return {"iterations": []} 

def save_evolution_data(data: Dict[str, List]):
    """Evrim verilerini JSON dosyasÄ±na kaydeder."""
    try:
        with open(EVOLUTION_DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except OSError as e:
        log.error(f"'{EVOLUTION_DATA_FILE}' dosyasÄ±na yazÄ±lamadÄ±: {e}")
    except Exception as e:
         log.error(f"Evrim verisi kaydedilirken beklenmedik hata: {e}", exc_info=True)

def analyze_past_cycles(data: Dict[str, List]) -> str:
    """YÃ¼klenen verilerden geÃ§miÅŸ geliÅŸtirme dÃ¶ngÃ¼lerini analiz eder."""
    iterations = data.get("iterations", [])
    if not iterations:
        return "GeÃ§miÅŸ veri yok."
    successful_tasks = sum(1 for iter_data in iterations if iter_data.get("success"))
    total_tasks = len(iterations)
    success_rate = (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0
    return f"Toplam {total_tasks} gÃ¶rev denendi, baÅŸarÄ± oranÄ±: %{success_rate:.1f}"

# --- ANA STRATEJÄ°K EVRÄ°M DÃ–NGÃœSÃœ ---

async def run_once() -> Dict[str, Any]:
    """
    BaseAI Stratejik Evrim DÃ¶ngÃ¼sÃ¼nÃ¼n tek bir iterasyonunu Ã§alÄ±ÅŸtÄ±rÄ±r.
    (Stratejik GÃ¶rev Manuel Olarak AtanmÄ±ÅŸ SÃ¼rÃ¼m)
    """
    start_time = time.monotonic()
    log.info("[AutoDev|StratejikEvrim] â–¶ï¸ Stratejik DÃ¶ngÃ¼ Ä°terasyonu BaÅŸlÄ±yor...")
    
    # NÄ°HAÄ° DÃœZELTME (UnboundLocalError): 'evolution_data'yÄ± try bloÄŸunun dÄ±ÅŸÄ±na taÅŸÄ±
    evolution_data = load_evolution_data()
    
    result: Dict[str, Any] = {
        "timestamp": time.time(), 
        "success": False, "task_type": "N/A", "task_target": "N/A",
        "task_description": "N/A", "files_generated": [], "files_lint_failed": [], 
        "files_git_blocked": [], "files_written": [], "files_failed_write": [], 
        "error": None, "duration_s": 0
    }
    
    # --- NÄ°HAÄ° DÃœZELTME (ReadTimeout): GÃ¶rev Ãœretme AdÄ±mÄ±nÄ± Atla ve Manuel GÃ¶rev Ata ---
    # Lokal LLM'in (Ollama) planlama (ReadTimeout) hatasÄ±nÄ± Ã¶nlemek iÃ§in
    # Kendi kendine yeterlilik (AÅŸama 1) gÃ¶revini manuel olarak enjekte et.
    task_type: str = "YENÄ°_MODÃœL"
    task_target_str: str = "baseai/core/code_analyzer.py"
    task_description: str = (
        "BaseAI'nin harici LLM'lere olan baÄŸÄ±mlÄ±lÄ±ÄŸÄ±nÄ± azaltmak iÃ§in ilk adÄ±mÄ± at. "
        "Python'un 'ast' (Abstract Syntax Tree) kÃ¼tÃ¼phanesini kullanarak, "
        "verilen bir Python kod dizesini analiz edebilen (parse) "
        "ve iÃ§indeki fonksiyonlarÄ±, sÄ±nÄ±flarÄ± ve import'larÄ± listeleyebilen "
        "temel bir 'CodeAnalyzer' sÄ±nÄ±fÄ± oluÅŸtur."
    )
    # --- Manuel GÃ¶rev AtamasÄ± Bitti ---

    target_file_paths = [re.sub(r'[`\'"]', '', p.strip()) for p in task_target_str.split(',') if p.strip()]

    try:
        # Lokal KÃ¶prÃ¼yÃ¼ (Ollama) kullan
        bridge = await local_llm_bridge() 
        
        # --- AdÄ±m 1 & 2: Analiz ve BaÄŸlam ---
        analysis_summary = analyze_past_cycles(evolution_data)
        log.info(f"[AutoDev|StratejikEvrim] GeÃ§miÅŸ Analizi: {analysis_summary}")
        
        code_context = await _get_codebase_context(BASE_AI_CORE_DIR, CONTEXT_IGNORE_DIRS, max_files=50)
        if "[HATA:" in code_context:
             result["error"] = "Failed to get codebase context."; return result

        # --- AdÄ±m 3: GÃ¶rev Ãœretimi (ATLANDI) ---
        result.update({
            "task_type": task_type,
            "task_description": task_description,
            "task_target": task_target_str
        })
        log.info(f"[AutoDev|StratejikEvrim] âœ… GÃ¶rev Manuel Olarak Belirlendi: [{task_type}] {task_target_str}") 

        # --- AdÄ±m 4 & 5: BaÄŸlam HazÄ±rlama ve GÃ¶rev YÃ¼rÃ¼tme ---
        execution_instruction: str = ""; execution_context: str = ""; execution_rules: List[str] = []
        
        if task_type == "YENÄ°_MODÃœL":
             if not target_file_paths or len(target_file_paths) != 1: 
                 result["error"] = "YENÄ°_MODÃœL iÃ§in tek hedef dosya gerekir."; return result
             
             target_file = target_file_paths[0] 
             execution_context = code_context # Mevcut proje yapÄ±sÄ±
             execution_instruction = (
                 f"**GÃ–REV TÄ°PÄ°:** {task_type}\n"
                 f"**OLUÅTURULACAK DOSYA:** `{target_file}`\n\n"
                 f"**GÃ–REV AÃ‡IKLAMASI:** {task_description}\n\n"
                 f"**MEVCUT PROJE YAPISI (Referans iÃ§in):**\n```\n{execution_context}\n```\n\n"
                 f"**Ä°STEK:** LÃ¼tfen `{target_file}` dosyasÄ± iÃ§in tam Python kodunu oluÅŸtur.\n\n"
                 f"**Ã‡IKTI FORMATI:** JSON (`{{ \"{target_file}\": \"tam_kod\" }}`)."
             )
             execution_rules = [
                 "[KESÄ°N] Ã‡Ä±ktÄ± formatÄ±: JSON.",
                 f"[KESÄ°N] JSON anahtarÄ±: `{target_file}`.",
                 "[KALÄ°TE] Python 3.11+ standartlarÄ±nda, type hinting kullanarak yaz.",
                 "[DOÄRULAMA] Kod `ruff ...` komutundan HATASIZ geÃ§melidir."
             ]
        else:
            # Bu manuel dÃ¶ngÃ¼de diÄŸer gÃ¶rev tipleri beklenmiyor
             log.error(f"Manuel olarak atanmÄ±ÅŸ bu dÃ¶ngÃ¼de desteklenmeyen gÃ¶rev tipi: {task_type}")
             result["error"] = f"Unsupported task type in manual override: {task_type}"; return result
        
        log.info(f"[AutoDev|StratejikEvrim] âš™ï¸ GÃ¶rev yÃ¼rÃ¼tÃ¼lÃ¼yor: {task_description[:100]}...")
        
        # Lokal model (Ollama) aracÄ±lÄ±ÄŸÄ±yla kod Ã¼retimi
        file_bundle = await bridge.generate_files(execution_instruction, execution_context, rules=execution_rules)

        # --- AdÄ±m 6, 7, 8: DoÄŸrulama, Lint, Yazma ---
        if not file_bundle or not isinstance(file_bundle, dict) or "error" in file_bundle:
            error_msg = file_bundle.get("error", "Lokal kÃ¶prÃ¼ hatasÄ±") if isinstance(file_bundle, dict) else "GeÃ§ersiz veya boÅŸ yanÄ±t (YÃ¼rÃ¼tme)"
            result["error"] = f"LLM failed during task execution: {error_msg}"; return result 
            
        result["files_generated"] = list(file_bundle.keys())
        generated_files_set = set(result["files_generated"])
        expected_files_exec = set(target_file_paths) 
        
        if not expected_files_exec.issubset(generated_files_set):
             log.error(f"[AutoDev|StratejikEvrim] âŒ Lokal LLM yÃ¼rÃ¼tme sonucu beklenen hedef dosyalarÄ± iÃ§ermiyor! Beklenen: {expected_files_exec}, DÃ¶nen: {generated_files_set}")
             result["error"] = "Lokal LLM yÃ¼rÃ¼tme sonucu beklenen hedef dosyalarÄ± iÃ§ermiyor!"; return result
             
        log.info(f"[AutoDev|StratejikEvrim] âœ… Lokal LLM'den {len(file_bundle)} dosyalÄ±k yÃ¼rÃ¼tme sonucu alÄ±ndÄ±.")

        files_to_write: Dict[str, str] = {}; abs_paths_to_commit: List[str] = [] 
        lint_failed_details: Dict[str, str] = {}
        
        for relative_path, content in file_bundle.items():
            if relative_path not in expected_files_exec: 
                 log.warning(f"[AutoDev|StratejikEvrim] âš ï¸ Lokal LLM beklenmeyen dosya dÃ¶ndÃ¼rdÃ¼, yoksayÄ±lÄ±yor: {relative_path}"); continue
                 
            lint_passed, lint_message, corrected_code = await _lint_code(content) 
            
            if not lint_passed:
                log.error(f"[AutoDev|StratejikEvrim] âŒ Ãœretilen kod LINT KONTROLÃœNÃœ GEÃ‡EMEDÄ°: {relative_path}. Mesaj: {lint_message}")
                result["files_lint_failed"].append(relative_path); lint_failed_details[relative_path] = lint_message; continue 

            content = corrected_code # Otomatik dÃ¼zeltilmiÅŸ kodu kullan

            abs_path = await _validate_and_normalize_path(relative_path)
            if not abs_path: 
                result["files_failed_write"].append(relative_path); continue 
            
            is_safe, git_status_msg = await _check_git_status(abs_path)
            if not is_safe:
                result["files_git_blocked"].append(relative_path); continue 
            
            files_to_write[relative_path] = content
            abs_paths_to_commit.append(abs_path) 

        if not files_to_write:
             error_parts = []
             if result["files_lint_failed"]: error_parts.append(f"{len(result['files_lint_failed'])} file(s) failed lint check")
             if result["files_git_blocked"]: error_parts.append(f"{len(result['files_git_blocked'])} file(s) blocked by Git status")
             result["error"] = "; ".join(error_parts) if error_parts else "No valid files generated or passed checks."
             result["success"] = False
        else:
            written_files, failed_write = await _write_files_to_disk(files_to_write)
            result["files_written"] = written_files
            result["files_failed_write"].extend(failed_write) 

            all_targets_written = expected_files_exec.issubset(set(written_files)) 
            no_failures = not result["files_lint_failed"] and not result["files_git_blocked"] and not result["files_failed_write"]
            
           
            if all_targets_written and no_failures:
                log.info("[AutoDev|StratejikEvrim] âœ… GÃ¶rev baÅŸarÄ±yla tamamlandÄ±, commit atÄ±lÄ±yor...")
                
                # --- AdÄ±m 9: Otomatik Commit ve Push ---
                commit_success = False
                if abs_paths_to_commit:
                    # _git_add_commit artÄ±k push iÅŸlemini de iÃ§eriyor ve baÅŸarÄ±/baÅŸarÄ±sÄ±zlÄ±k dÃ¶ndÃ¼rÃ¼yor
                    commit_success = await _git_add_commit(abs_paths_to_commit, result['task_description'])
                
                if commit_success:
                    result["success"] = True
                    log.info("[AutoDev|StratejikEvrim] âœ… GÃ¶rev baÅŸarÄ±yla GitHub'a kaydedildi.")
                else:
                    # EÄER COMMIT VEYA PUSH BAÅARISIZ OLURSA (Ã¶rn: Colab Yetki HatasÄ±):
                    result["success"] = False
                    result["error"] = "Task completed but failed to commit or push to GitHub."
                    log.error("[AutoDev|StratejikEvrim] âŒ GÃ¶rev tamamlandÄ± ancak GitHub'a push edilemedi.")

            else: # KÄ±smi baÅŸarÄ± veya tam baÅŸarÄ±sÄ±zlÄ±k (Lint, Git, Yazma)
                result["success"] = False
                errors = []
                if result["files_lint_failed"]: errors.append(f"{len(result['files_lint_failed'])} lint errors")
                if result["files_git_blocked"]: errors.append(f"{len(result['files_git_blocked'])} Git blocks")
                if result["files_failed_write"]: errors.append(f"{len(result['files_failed_write'])} write errors")
                if not all_targets_written: errors.append("Not all targets written")
                result["error"] = "; ".join(errors) if errors else "Unknown validation/write failure"
                log.error(f"[AutoDev|StratejikEvrim] âŒ GÃ¶rev tamamlanamadÄ±. Hatalar: {result['error']}")
                if lint_failed_details:
                     log.error("[AutoDev|StratejikEvrim] Lint Hata DetaylarÄ±:")
                     for fname, msg in lint_failed_details.items():
                          log.error(f"  File: {fname} -> {msg}")
      

    except Exception as e:
        detailed_error = traceback.format_exc()
        log.critical(f"[AutoDev|StratejikEvrim] ğŸ’¥ DÃ¶ngÃ¼de beklenmeyen kritik hata: {e}\n{detailed_error}")
        result["error"] = f"CRITICAL_EVOLUTION_FAILURE: {e}"
        result["success"] = False

    finally:
        end_time = time.monotonic(); duration = end_time - start_time
        result["duration_s"] = round(duration, 2)
        
        # 'evolution_data' artÄ±k burada her zaman tanÄ±mlÄ±
        evolution_data.setdefault("iterations", []).append(result)
        save_evolution_data(evolution_data)
        
        status = "BAÅARILI" if result.get("success", False) else "BAÅARISIZ"
        log.info(f"--- [AutoDev|StratejikEvrim] Ä°TERASYON SONUCU ---")
        log.info(f" Durum: {status}"); 
        log.info(f" GÃ¶rev Tipi: {result.get('task_type', 'N/A')}") 
        log.info(f" Hedef(ler): {result.get('task_target', 'N/A')}")
        log.info(f" AÃ§Ä±klama: {result.get('task_description', 'N/A')[:150]}...")
        log.info(f" Ãœretilen: {len(result.get('files_generated',[]))}, YazÄ±lan: {len(result.get('files_written',[]))}")
        log.info(f" BaÅŸarÄ±sÄ±z (Lint/Git/Yazma): {len(result.get('files_lint_failed',[]))}/{len(result.get('files_git_blocked',[]))}/{len(result.get('files_failed_write',[]))}")
        log.info(f" SÃ¼re: {duration:.2f}s")
        if result.get("error"): log.error(f" Hata DetayÄ±: {result.get('error')}")
        log.info(f"--- Ä°TERASYON SONUCU BÄ°TTÄ° ---")
             
    return result

# --- Refleks DÃ¶ngÃ¼sÃ¼ BaÅŸlatÄ±cÄ±sÄ± (Enterprise Loop gibi) ---
async def start_evolution_loop(
    loop_func: Callable[[], Awaitable[Dict[str, Any]]] = run_once,
    success_delay_sec: float = 900.0, # 15 dakika
    error_delay_sec: float = 60.0    # 1 dakika
):
    """Refleks dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlatÄ±r."""
    log.info(f"ğŸ” BaseAI Stratejik Evrim DÃ¶ngÃ¼sÃ¼ BaÅŸlatÄ±lÄ±yor (Fonksiyon: '{loop_func.__name__}').")
    log.info(f"   BaÅŸarÄ± SonrasÄ± Bekleme: {success_delay_sec} saniye")
    log.info(f"   Hata SonrasÄ± Bekleme  : {error_delay_sec} saniye")
    
    loop_count = 0
    while True: # Sonsuz dÃ¶ngÃ¼ (Ctrl+C ile durdurulur)
        loop_count += 1
        log.info(f"[Loop #{loop_count}] Yeni stratejik evrim iterasyonu baÅŸlÄ±yor...")
        
        iteration_result = {}
        try:
            iteration_result = await loop_func()
            status = iteration_result.get("success", False)
            error_detail = iteration_result.get("error", None)
            duration = iteration_result.get("duration_s", 0)
            
            if status:
                log.info(f"[Loop #{loop_count}] Ä°terasyon tamamlandÄ±. Durum: BAÅARILI. SÃ¼re: {duration:.2f}s.")
                delay = success_delay_sec
            else:
                log.info(f"[Loop #{loop_count}] Ä°terasyon tamamlandÄ±. Durum: BAÅARISIZ ({error_detail}). SÃ¼re: {duration:.2f}s.")
                delay = error_delay_sec
                
            log.info(f"[Loop #{loop_count}] Sonraki iterasyon iÃ§in {delay} saniye bekleniyor...")
            await asyncio.sleep(delay)

        except asyncio.CancelledError:
            log.warning(f"[Loop #{loop_count}] DÃ¶ngÃ¼ iterasyonu iptal edildi (kapatma isteÄŸi).")
            break # DÃ¶ngÃ¼den Ã§Ä±k
        except Exception as e:
            # DÃ¶ngÃ¼ fonksiyonunun kendisinde beklenmedik hata
            log.critical(f"[Loop #{loop_count}|FATAL] DÃ¶ngÃ¼ fonksiyonu '{loop_func.__name__}' kritik hata verdi: {e}", exc_info=True)
            log.info(f"[Loop #{loop_count}] Kritik hata sonrasÄ± {error_delay_sec} saniye bekleniyor...")
            await asyncio.sleep(error_delay_sec)


if __name__ == '__main__':
    try:
        # Ana asenkron dÃ¶ngÃ¼yÃ¼ baÅŸlat
        asyncio.run(start_evolution_loop())
    except KeyboardInterrupt:
        log.info("KullanÄ±cÄ± tarafÄ±ndan durduruldu.")
    finally:
        log.info("ğŸ BaseAI Stratejik Evrim DÃ¶ngÃ¼sÃ¼ KapatÄ±ldÄ±.")